{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Lab1-Regression_MLP.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sydrafaey/restaurant-management-app/blob/main/Copy_of_Lab1_Regression_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDIkviIMOBgX"
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing() # loading the California Housing dataset\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42) # test and train\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42) # training and validation\n",
        "\n",
        "# Using the StandardScaler to scale the dataset\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA5nDCjIGSCm",
        "outputId": "fa86374f-28f9-4a27-e645-c66ddf82c4e3"
      },
      "source": [
        "housing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block\\n        - HouseAge      median house age in block\\n        - AveRooms      average number of rooms\\n        - AveBedrms     average number of bedrooms\\n        - Population    block population\\n        - AveOccup      average house occupancy\\n        - Latitude      house block latitude\\n        - Longitude     house block longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttp://lib.stat.cmu.edu/datasets/\\n\\nThe target variable is the median house value for California districts.\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n',\n",
              " 'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
              "           37.88      , -122.23      ],\n",
              "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
              "           37.86      , -122.22      ],\n",
              "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
              "           37.85      , -122.24      ],\n",
              "        ...,\n",
              "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
              "           39.43      , -121.22      ],\n",
              "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
              "           39.43      , -121.32      ],\n",
              "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
              "           39.37      , -121.24      ]]),\n",
              " 'feature_names': ['MedInc',\n",
              "  'HouseAge',\n",
              "  'AveRooms',\n",
              "  'AveBedrms',\n",
              "  'Population',\n",
              "  'AveOccup',\n",
              "  'Latitude',\n",
              "  'Longitude'],\n",
              " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Enb8jRXSOVOu",
        "outputId": "9ef62005-a27a-4b1b-f7f1-7aceb1261522"
      },
      "source": [
        "\n",
        "X_train.shape, X_valid.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11610, 8), (3870, 8), (5160, 8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju7VvPIJOYsN"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "np.random.seed(42) # generating random see\n",
        "tf.random.set_seed(42) # setting random seed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9psH8PHTOb71",
        "outputId": "301252b8-dc6d-4754-e109-7ab945c7c8cf"
      },
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3)) # compiling the model\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid)) # fit the model\n",
        "mse_test = model.evaluate(X_test, y_test) # evaluating\n",
        "X_new = X_test[:3]\n",
        "y_pred = model.predict(X_new) # predicting"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.6419 - val_loss: 0.8560\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.7047 - val_loss: 0.6531\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.6345 - val_loss: 0.6099\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5977 - val_loss: 0.5658\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5706 - val_loss: 0.5355\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5472 - val_loss: 0.5173\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5288 - val_loss: 0.5081\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5130 - val_loss: 0.4799\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4992 - val_loss: 0.4690\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4875 - val_loss: 0.4656\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4777 - val_loss: 0.4482\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4688 - val_loss: 0.4479\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4615 - val_loss: 0.4296\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4547 - val_loss: 0.4233\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4488 - val_loss: 0.4176\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4435 - val_loss: 0.4123\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4389 - val_loss: 0.4071\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4347 - val_loss: 0.4037\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4306 - val_loss: 0.4000\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4273 - val_loss: 0.3969\n",
            "162/162 [==============================] - 0s 855us/step - loss: 0.4212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxlzNQMMO9up",
        "outputId": "dad37ae7-2dd3-455f-bb41-1dd16d72db78"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 30)                270       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 301\n",
            "Trainable params: 301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "rPcmfzNTPC8m",
        "outputId": "01c40dd6-41ff-4aea-996f-7d8d5617a006"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "plt.plot(pd.DataFrame(history.history))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1) # setting y-axis limit\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMmGSqSdsdhY",
        "outputId": "41038e3d-0613-4277-9655-af658434fc39"
      },
      "source": [
        "y_pred # printing the predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.38856643],\n",
              "       [1.6792021 ],\n",
              "       [3.1022797 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTbFnokJunN5"
      },
      "source": [
        "Functional API\n",
        "\n",
        "Not all neural network models are simply sequential. Some may have complex topologies. Some may have multiple inputs and/or multiple outputs. For example, a Wide & Deep neural network (see paper) connects all or part of the inputs directly to the output layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nBqZiqcvZ0F"
      },
      "source": [
        "# Defining the layers\n",
        "\n",
        "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
        "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
        "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
        "concat = keras.layers.concatenate([input_, hidden2]) # concatenate inputs\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "model = keras.models.Model(inputs=[input_], outputs=[output])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKR_p9Lpvh9u",
        "outputId": "b87e2fb4-73ab-45a1-9bb1-8a536c1047a5"
      },
      "source": [
        "model.summary() # generating model summary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 30)           270         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 30)           930         dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 38)           0           input_1[0][0]                    \n",
            "                                                                 dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            39          concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 1,239\n",
            "Trainable params: 1,239\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdT67O-GvlTd",
        "outputId": "a040e849-e2c2-4d70-b602-8659468386f5"
      },
      "source": [
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3)) # compile model\n",
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data=(X_valid, y_valid)) # fit model\n",
        "mse_test = model.evaluate(X_test, y_test) # evaluate model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 3.2566 - val_loss: 0.6913\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.6795 - val_loss: 0.9454\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.6284 - val_loss: 0.6622\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5929 - val_loss: 0.5284\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5452 - val_loss: 0.5004\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5313 - val_loss: 0.5894\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5207 - val_loss: 0.5889\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4938 - val_loss: 0.4690\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4789 - val_loss: 0.5305\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4728 - val_loss: 0.5466\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4614 - val_loss: 0.4996\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4521 - val_loss: 0.7264\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4522 - val_loss: 0.4205\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4421 - val_loss: 0.4467\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4467 - val_loss: 0.4167\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4471 - val_loss: 0.4486\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4312 - val_loss: 0.4021\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4313 - val_loss: 0.3991\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4096 - val_loss: 0.4348\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4032 - val_loss: 0.3965\n",
            "162/162 [==============================] - 0s 841us/step - loss: 0.4164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Scj8eVPGvomL"
      },
      "source": [
        "\n",
        "y_pred = model.predict(X_test) # predict using the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZUbAZgYvsD4",
        "outputId": "db247099-88c9-447f-9f88-3286b6c034c7"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.43743038],\n",
              "       [1.7257447 ],\n",
              "       [3.4477878 ],\n",
              "       ...,\n",
              "       [1.4218006 ],\n",
              "       [2.5358925 ],\n",
              "       [3.8148327 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKP2-eIgvu0q"
      },
      "source": [
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o61fN2WWB86"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AcX_xRIv0Iy"
      },
      "source": [
        "# creating the model using different number of layers\n",
        "\n",
        "\n",
        "input_A = keras.layers.Input(shape=[5], name=\"wide_input\") #return a tensor input_A\n",
        "input_B = keras.layers.Input(shape=[6], name=\"deep_input\") #return a tensor input_B\n",
        "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B) #\n",
        "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
        "concat = keras.layers.concatenate([input_A, hidden2]) # concatenate inputs\n",
        "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
        "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekT_tx4vv3CE",
        "outputId": "20012b8d-4870-407e-a28b-b994637ef72e"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11610, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyY6JscYv5rF",
        "outputId": "bf7ddba6-5e4e-45b4-ce39-9d415f15317f"
      },
      "source": [
        "[1,2,3,4][2:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPXG07Avv7--",
        "outputId": "900292ea-a396-4161-93a0-0f0ada236120"
      },
      "source": [
        "\n",
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3)) # compile the model\n",
        "\n",
        "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
        "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
        "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
        "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
        "\n",
        "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
        "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
        "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
        "y_pred = model.predict((X_new_A, X_new_B))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 3.1941 - val_loss: 0.8072\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.7247 - val_loss: 0.6658\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.6176 - val_loss: 0.5687\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5799 - val_loss: 0.5296\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5409 - val_loss: 0.4993\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5173 - val_loss: 0.4811\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5186 - val_loss: 0.4696\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4977 - val_loss: 0.4496\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4765 - val_loss: 0.4404\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4676 - val_loss: 0.4315\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4574 - val_loss: 0.4268\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4479 - val_loss: 0.4166\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4487 - val_loss: 0.4125\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4469 - val_loss: 0.4074\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4460 - val_loss: 0.4044\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4495 - val_loss: 0.4007\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4378 - val_loss: 0.4013\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4375 - val_loss: 0.3987\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4151 - val_loss: 0.3934\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4078 - val_loss: 0.4204\n",
            "162/162 [==============================] - 0s 1ms/step - loss: 0.4219\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbOUKFnnwDMF"
      },
      "source": [
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vxf3nYJ7wTRl"
      },
      "source": [
        "\n",
        "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
        "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
        "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
        "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
        "concat = keras.layers.concatenate([input_A, hidden2]) # concatenate the inputs\n",
        "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
        "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2) # aux output for regularization\n",
        "model = keras.models.Model(inputs=[input_A, input_B],\n",
        "                           outputs=[output, aux_output])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLObDospwVPx"
      },
      "source": [
        "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3)) # compile the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "GeB2TodXwX8o",
        "outputId": "cdda6fe7-a2da-42e6-82e9-3fd6eac59f75"
      },
      "source": [
        "\n",
        "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
        "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid])) # fit the model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 3.4633 - main_output_loss: 3.3289 - aux_output_loss: 4.6732 - val_loss: 1.6233 - val_main_output_loss: 0.8468 - val_aux_output_loss: 8.6117\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.9807 - main_output_loss: 0.7503 - aux_output_loss: 3.0537 - val_loss: 1.5163 - val_main_output_loss: 0.6836 - val_aux_output_loss: 9.0109\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.7742 - main_output_loss: 0.6290 - aux_output_loss: 2.0810 - val_loss: 1.4639 - val_main_output_loss: 0.6229 - val_aux_output_loss: 9.0326\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6952 - main_output_loss: 0.5897 - aux_output_loss: 1.6449 - val_loss: 1.3388 - val_main_output_loss: 0.5481 - val_aux_output_loss: 8.4552\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6469 - main_output_loss: 0.5508 - aux_output_loss: 1.5118 - val_loss: 1.2177 - val_main_output_loss: 0.5194 - val_aux_output_loss: 7.5030\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6120 - main_output_loss: 0.5251 - aux_output_loss: 1.3943 - val_loss: 1.0935 - val_main_output_loss: 0.5106 - val_aux_output_loss: 6.3396\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6114 - main_output_loss: 0.5256 - aux_output_loss: 1.3833 - val_loss: 0.9918 - val_main_output_loss: 0.5115 - val_aux_output_loss: 5.3151\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5765 - main_output_loss: 0.5024 - aux_output_loss: 1.2439 - val_loss: 0.8733 - val_main_output_loss: 0.4733 - val_aux_output_loss: 4.4740\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5535 - main_output_loss: 0.4811 - aux_output_loss: 1.2057 - val_loss: 0.7832 - val_main_output_loss: 0.4555 - val_aux_output_loss: 3.7323\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5456 - main_output_loss: 0.4708 - aux_output_loss: 1.2189 - val_loss: 0.7170 - val_main_output_loss: 0.4604 - val_aux_output_loss: 3.0262\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5297 - main_output_loss: 0.4587 - aux_output_loss: 1.1684 - val_loss: 0.6510 - val_main_output_loss: 0.4293 - val_aux_output_loss: 2.6468\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5181 - main_output_loss: 0.4501 - aux_output_loss: 1.1305 - val_loss: 0.6051 - val_main_output_loss: 0.4310 - val_aux_output_loss: 2.1722\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5100 - main_output_loss: 0.4487 - aux_output_loss: 1.0620 - val_loss: 0.5644 - val_main_output_loss: 0.4161 - val_aux_output_loss: 1.8992\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5064 - main_output_loss: 0.4459 - aux_output_loss: 1.0503 - val_loss: 0.5354 - val_main_output_loss: 0.4119 - val_aux_output_loss: 1.6466\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5027 - main_output_loss: 0.4452 - aux_output_loss: 1.0207 - val_loss: 0.5124 - val_main_output_loss: 0.4047 - val_aux_output_loss: 1.4812\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5057 - main_output_loss: 0.4480 - aux_output_loss: 1.0249 - val_loss: 0.4934 - val_main_output_loss: 0.4034 - val_aux_output_loss: 1.3035\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4931 - main_output_loss: 0.4360 - aux_output_loss: 1.0075 - val_loss: 0.4801 - val_main_output_loss: 0.3984 - val_aux_output_loss: 1.2150\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4922 - main_output_loss: 0.4352 - aux_output_loss: 1.0053 - val_loss: 0.4694 - val_main_output_loss: 0.3962 - val_aux_output_loss: 1.1279\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4658 - main_output_loss: 0.4139 - aux_output_loss: 0.9323 - val_loss: 0.4580 - val_main_output_loss: 0.3936 - val_aux_output_loss: 1.0372\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4589 - main_output_loss: 0.4072 - aux_output_loss: 0.9243 - val_loss: 0.4655 - val_main_output_loss: 0.4048 - val_aux_output_loss: 1.0118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "944n7aTswaPi",
        "outputId": "b00eea31-50e1-400d-ae06-e47336b15fab"
      },
      "source": [
        "\n",
        "total_loss, main_loss, aux_loss = model.evaluate(\n",
        "    [X_test_A, X_test_B], [y_test, y_test])\n",
        "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B]) # predicting using aux layer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162/162 [==============================] - 0s 1ms/step - loss: 0.4668 - main_output_loss: 0.4178 - aux_output_loss: 0.9082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onDyz1zpwooE"
      },
      "source": [
        "model = WideAndDeepModel(30, activation=\"relu\") # creating an instance of the WideAndDeepModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq0zaB_Uwr48"
      },
      "source": [
        "Saving and Restoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W9n6T5dwuZY"
      },
      "source": [
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59Rx8S5IwxFD"
      },
      "source": [
        "# creating a model to demonstrate saving and restoring\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
        "    keras.layers.Dense(30, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lB987vpLw2oN",
        "outputId": "856774d1-1221-4aaf-ba9b-73fadecb2168"
      },
      "source": [
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3)) # compile the model\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid)) # fit the model\n",
        "mse_test = model.evaluate(X_test, y_test) # evalutate the model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 3.3697 - val_loss: 0.7126\n",
            "Epoch 2/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6964 - val_loss: 0.6880\n",
            "Epoch 3/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.6167 - val_loss: 0.5803\n",
            "Epoch 4/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5846 - val_loss: 0.5166\n",
            "Epoch 5/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5321 - val_loss: 0.4895\n",
            "Epoch 6/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5083 - val_loss: 0.4951\n",
            "Epoch 7/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5044 - val_loss: 0.4861\n",
            "Epoch 8/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4813 - val_loss: 0.4554\n",
            "Epoch 9/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4627 - val_loss: 0.4413\n",
            "Epoch 10/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4549 - val_loss: 0.4379\n",
            "162/162 [==============================] - 0s 1ms/step - loss: 0.4382\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI00Gp2Fw5Bj"
      },
      "source": [
        "\n",
        "model.save(\"my_keras_model.h5\") # Saving the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGaEVNVGw7yr",
        "outputId": "f1f8fe2f-9723-4920-d07f-c6697041e58a"
      },
      "source": [
        "!strings my_keras_model.h5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TREE\n",
            "HEAP\n",
            "model_weights\n",
            "optimizer_weights\n",
            "keras_version\n",
            "backend\n",
            "model_config\n",
            "training_config\n",
            "TREE\n",
            "HEAP\n",
            "dense_18\n",
            "dense_19\n",
            "dense_20\n",
            "layer_names\n",
            "dense_18dense_19dense_20\n",
            "GCOL\n",
            "2.4.0\n",
            "tensorflow\n",
            "{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_1\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 8], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"dense_18_input\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_18\", \"trainable\": true, \"batch_input_shape\": [null, 8], \"dtype\": \"float32\", \"units\": 30, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_19\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 30, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_20\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 1, \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}}\n",
            "{\"loss\": \"mse\", \"metrics\": null, \"weighted_metrics\": null, \"loss_weights\": null, \"optimizer_config\": {\"class_name\": \"SGD\", \"config\": {\"name\": \"SGD\", \"learning_rate\": 0.0010000000474974513, \"decay\": 0.0, \"momentum\": 0.0, \"nesterov\": false}}}\n",
            "tensorflow\n",
            "2.4.0\n",
            "SNOD\n",
            "backend\n",
            "keras_version\n",
            "TREE\n",
            "HEAP\n",
            "dense_18\n",
            "SNOD\n",
            "weight_names\n",
            "dense_18/kernel:0dense_18/bias:0\n",
            "TREE\n",
            "HEAP\n",
            "kernel:0\n",
            "bias:0\n",
            "SNOD\n",
            "SNOD\n",
            ".>jhw\n",
            ",t>Y\t\n",
            "(sb>\n",
            "?K@>\n",
            "=@.0>\n",
            "y<>s\n",
            "F>Fm\n",
            "Z>/^\n",
            "a>cvC\n",
            "6>m\"\n",
            "5yM=\n",
            "MO>5\n",
            "\tcy>\n",
            ";8^!\n",
            "=t^z>\n",
            "z'p<\n",
            "b=O8\n",
            "&o=!\n",
            "~>`M\n",
            "4>WQ\n",
            "Y;yi*?l\n",
            "TREE\n",
            "HEAP\n",
            "dense_19\n",
            "weight_names\n",
            "dense_19/kernel:0dense_19/bias:0\n",
            "TREE\n",
            "HEAP\n",
            "kernel:0\n",
            "bias:0\n",
            "SNOD\n",
            "SNOD\n",
            "c>M1p\n",
            "e>)%{>\n",
            "I>_[\n",
            "A5h>\n",
            "=wpP\n",
            "Y?L>\n",
            "No<>\n",
            "uW>9\n",
            "#c>V\n",
            "=<Ld>x![\n",
            "Jm<G\n",
            "Zk>.\n",
            ">j4@\n",
            "My%>z\n",
            "=UOL>2\n",
            "2~>=\n",
            "&=K\",\n",
            "6>=r\n",
            "-w>q\n",
            "&kl>G9\n",
            "0f>M\"<\n",
            "@>)O4>U<9>+=_\n",
            ">2u+>#\n",
            ":=BO\n",
            "=OQj\n",
            "Fh=6\n",
            "3m/>\n",
            "@d>M(\n",
            ">[j/>x!\n",
            "M>x1\n",
            "&g<D\n",
            "sP>]\n",
            "\t>g1;>\n",
            "h)>K\n",
            "^>ka\n",
            "=W%4\n",
            "=Q9Y\n",
            ">t|^\n",
            "\t\t>A\n",
            "i;AE*=\n",
            "Jx2>XT\n",
            "uWD>\n",
            "Ii4>\n",
            "=aX,>vyA>w\n",
            "n>W/->\n",
            "d`#>\n",
            "D{>Y\n",
            "pW->>Zu\n",
            ">I3`\n",
            "v=Vj;=\n",
            "9A/a\n",
            "[C>%p\n",
            "iB'>\n",
            "0< U\n",
            "E<p2\n",
            ">OaA\n",
            "d=&I\n",
            "=piT>\n",
            "~8>v\n",
            "TREE\n",
            "HEAP\n",
            "dense_20\n",
            "weight_names\n",
            "dense_20/kernel:0dense_20/bias:0\n",
            "TREE\n",
            "HEAP\n",
            "kernel:0\n",
            "bias:0\n",
            "SNOD\n",
            "SNOD\n",
            "TREE\n",
            "HEAP\n",
            "weight_names\n",
            "SGD/iter:0\n",
            "TREE\n",
            "HEAP\n",
            "iter:0\n",
            "SNOD\n",
            "SNOD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT9GpdWXw-Uz"
      },
      "source": [
        "model1 = keras.models.load_model(\"my_keras_model.h5\") # Loading the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ecr_fVXmxBZv",
        "outputId": "dd7350bf-bf01-4516-87ed-783017068c00"
      },
      "source": [
        "model.predict(X_new) # predicting using the model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 166 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4f61c7c830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5400236],\n",
              "       [1.6505969],\n",
              "       [3.009824 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SspYrmOyxDjn"
      },
      "source": [
        "\n",
        "model.save_weights(\"my_keras_weights.ckpt\") # saving the weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIzxlwJkxF4b"
      },
      "source": [
        "\n",
        "model.load_weights(\"my_keras_weights.ckpt\") # loading the saved weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSlqXV9lxIEL"
      },
      "source": [
        "Using Callbacks during Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZToqO70VxKZt"
      },
      "source": [
        "# Clearing previous session and\n",
        "# generating random seed and setting\n",
        "# the random seed\n",
        "\n",
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2_xikeWxP2m"
      },
      "source": [
        "\n",
        "# Defining the model to demostrate callbacks\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
        "    keras.layers.Dense(30, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MGoDqFOxTXE",
        "outputId": "7c99ce62-b569-46be-db23-ba55b0910fd2"
      },
      "source": [
        "\n",
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True) # saving the best model checkpoint\n",
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb]) # using the callback\n",
        "model = keras.models.load_model(\"my_keras_model.h5\") # rollback to best model\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 3.3697 - val_loss: 0.7126\n",
            "Epoch 2/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.6964 - val_loss: 0.6880\n",
            "Epoch 3/10\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.6167 - val_loss: 0.5803\n",
            "Epoch 4/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5846 - val_loss: 0.5166\n",
            "Epoch 5/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5321 - val_loss: 0.4895\n",
            "Epoch 6/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5083 - val_loss: 0.4951\n",
            "Epoch 7/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5044 - val_loss: 0.4861\n",
            "Epoch 8/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4813 - val_loss: 0.4554\n",
            "Epoch 9/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4627 - val_loss: 0.4413\n",
            "Epoch 10/10\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4549 - val_loss: 0.4379\n",
            "162/162 [==============================] - 0s 911us/step - loss: 0.4382\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDeQqZkoxZtj",
        "outputId": "e62eaee7-d252-4f24-9a2d-2fbd63ebdb8e"
      },
      "source": [
        "!ls my_keras_model.h5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_keras_model.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQOOpwf7xcj3",
        "outputId": "dcee7dcf-55b3-4754-b7d1-39199aaa6318"
      },
      "source": [
        "\n",
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5,\n",
        "                                                  restore_best_weights=True) # saving early stopping\n",
        "history = model.fit(X_train, y_train, epochs=100,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb]) # using the callback for checkpoint, and early stopping\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4578 - val_loss: 0.4110\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4430 - val_loss: 0.4266\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4376 - val_loss: 0.3996\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4361 - val_loss: 0.3939\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4204 - val_loss: 0.3889\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4112 - val_loss: 0.3866\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4226 - val_loss: 0.3860\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4135 - val_loss: 0.3793\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4039 - val_loss: 0.3746\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4023 - val_loss: 0.3723\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3950 - val_loss: 0.3697\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3912 - val_loss: 0.3669\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3939 - val_loss: 0.3661\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3868 - val_loss: 0.3631\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3878 - val_loss: 0.3660\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3935 - val_loss: 0.3625\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3817 - val_loss: 0.3592\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3801 - val_loss: 0.3563\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3679 - val_loss: 0.3535\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3624 - val_loss: 0.3709\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3746 - val_loss: 0.3512\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3605 - val_loss: 0.3699\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3822 - val_loss: 0.3476\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3626 - val_loss: 0.3561\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3610 - val_loss: 0.3527\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3626 - val_loss: 0.3701\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3685 - val_loss: 0.3432\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3684 - val_loss: 0.3592\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3581 - val_loss: 0.3521\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3687 - val_loss: 0.3626\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3613 - val_loss: 0.3431\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3555 - val_loss: 0.3766\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3621 - val_loss: 0.3374\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3502 - val_loss: 0.3407\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3471 - val_loss: 0.3614\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3451 - val_loss: 0.3348\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3780 - val_loss: 0.3573\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3474 - val_loss: 0.3367\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3689 - val_loss: 0.3425\n",
            "Epoch 40/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3485 - val_loss: 0.3369\n",
            "Epoch 41/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3674 - val_loss: 0.3514\n",
            "162/162 [==============================] - 0s 1ms/step - loss: 0.3545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGk6pQAWxjHN",
        "outputId": "c867d5c7-b661-4876-8c15-aa380fda9574"
      },
      "source": [
        "mse_test = model.evaluate(X_valid, y_valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "121/121 [==============================] - 0s 1ms/step - loss: 0.3348\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}