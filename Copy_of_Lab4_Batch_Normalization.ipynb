{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Lab4-Batch_Normalization.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sydrafaey/restaurant-management-app/blob/main/Copy_of_Lab4_Batch_Normalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaSMNWuUz2hh"
      },
      "source": [
        "Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9uwm6Mb0jXo",
        "outputId": "e1e8110c-1d1b-4aa8-b8b0-9616510763c0"
      },
      "source": [
        "# loading the Fashion-MNIST dataset\n",
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# trimming the data since it takes lot of time\n",
        "X_train_full = X_train_full[:30000]\n",
        "y_train_full = y_train_full[:30000]\n",
        "\n",
        "X_test = X_test[:5000]\n",
        "y_test = y_test[:5000]\n",
        "\n",
        "# scaling the dataset\n",
        "X_train_full = X_train_full / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# dividing the dataset into traingin and validation set\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_IoBoojz5ld"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "# creating a model\n",
        "# applying BN after every hidden layer and as the first\n",
        "# layer in the model (after flattening the input images)\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "   # keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "   # keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "   # keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCVc926U0MNo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d465823b-5cd5-4da5-8641-e212cb7b4f2d"
      },
      "source": [
        "# checking model layer details\n",
        "bn1 = model.layers[1]\n",
        "[(var.name, var.trainable) for var in bn1.variables]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('dense/kernel:0', True), ('dense/bias:0', True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndzpWnrp0Rp2"
      },
      "source": [
        "# compiling the model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh3isAbu0ag4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e880c16-e2f2-4cc9-cd32-f995384bae7a"
      },
      "source": [
        "\n",
        "# training the model\n",
        "history = model.fit(X_train, y_train, epochs=5,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.0171 - accuracy: 0.3486 - val_loss: 1.3473 - val_accuracy: 0.6668\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 3s 3ms/step - loss: 1.2581 - accuracy: 0.6581 - val_loss: 0.9980 - val_accuracy: 0.7006\n",
            "Epoch 3/5\n",
            "147/782 [====>.........................] - ETA: 1s - loss: 1.0173 - accuracy: 0.6942"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}